{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import flowkit as fk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(input_a,input_b,input_c): # diff\n",
    "    get_dist_ab=float(np.sqrt(sum(np.power(input_a-input_b,2))))\n",
    "    get_dist_ac=float(np.sqrt(sum(np.power(input_a-input_c,2))))\n",
    "    return abs(get_dist_ab-get_dist_ac)\n",
    "\n",
    "def compute_single_dist(input_a,input_c): # same\n",
    "    get_dist_ac=float(np.sqrt(sum(np.power(input_a-input_c,2))))\n",
    "    return get_dist_ac\n",
    "\n",
    "def compute_age(input_a,input_b,input_c): # diff\n",
    "    return abs(input_b-abs(input_a-input_c))\n",
    "\n",
    "def compute_single_age(input_a,input_c):# same\n",
    "    return abs(input_a-input_c)\n",
    "\n",
    "\n",
    "def random_feats(X: np.ndarray,\n",
    "                gamma: Union[int, float] = 1,\n",
    "                frequency_seed: int = None,sub_dim:int=None):\n",
    "    scale = 1 / gamma\n",
    "\n",
    "    if (frequency_seed is not None):\n",
    "        np.random.seed(frequency_seed)\n",
    "        W = np.random.normal(scale = scale, size = (X.shape[1], sub_dim))\n",
    "    else:\n",
    "        W = np.random.normal(scale = scale, size = (X.shape[1], sub_dim))\n",
    "\n",
    "    XW = np.dot(X, W)\n",
    "    sin_XW = np.sin(XW)\n",
    "    cos_XW = np.cos(XW)\n",
    "    phi = np.concatenate((cos_XW, sin_XW), axis=1)\n",
    "\n",
    "    return phi\n",
    "\n",
    "def preread_file(in_rff_dict,in_path,in_fcs_path,inget_marker,fcs_csv,in_median_max_pooling):\n",
    "    get_file_name=pd.read_csv(in_path)\n",
    "    for data_line in get_file_name['file_id']:\n",
    "        if fcs_csv == 'fcs':\n",
    "            sample = fk.Sample(in_fcs_path+str(data_line),ignore_offset_error=True)\n",
    "            dm = sample._get_raw_events()\n",
    "            CNames_pns = np.array(sample.pns_labels)\n",
    "            data_dff=pd.DataFrame(dm,columns=CNames_pns)\n",
    "            df_single=np.arcsinh(1./5 * data_dff[inget_marker])\n",
    "        else:\n",
    "            df_single = pd.read_csv(in_fcs_path+str(data_line))\n",
    "            dfv_0_arr=np.array(df_single[inget_marker])\n",
    "            df_single=np.arcsinh(1./5 * dfv_0_arr)\n",
    "        gettrf=random_feats(X=df_single,sub_dim=400) \n",
    "        if in_median_max_pooling=='max':\n",
    "            gettrf=np.max(gettrf, axis=0)\n",
    "        elif in_median_max_pooling=='mean':\n",
    "            gettrf=np.mean(gettrf, axis=0)\n",
    "        else:\n",
    "            gettrf=np.median(gettrf, axis=0)\n",
    "        \n",
    "        in_rff_dict[data_line]=gettrf\n",
    "    return in_rff_dict\n",
    "\n",
    "\n",
    "def read_files(input_path_base,input_path,input_id_lst,input_label_lst,input_co_lst,input_rff,inrff_vector, in_covariate_label):\n",
    "    with open(input_path_base+input_path, 'r') as j:\n",
    "        data = j.read()\n",
    "    data=data.split('\\n')\n",
    "    # print(data)\n",
    "    \n",
    "    for data_line in data:\n",
    "        data_split=data_line.split(',')\n",
    "        if data_split[0]=='fcs_filename':\n",
    "            covariate_label_index=data_split.index(in_covariate_label)\n",
    "            continue\n",
    "        input_id_lst.append(data_split[0])\n",
    "        input_label_lst.append(data_split[1])\n",
    "        input_co_lst.append(data_split[covariate_label_index]) \n",
    "        input_rff.append(inrff_vector[data_split[0]])\n",
    "    return input_id_lst,input_label_lst,input_co_lst,input_rff\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "def generate_cytocoset_RFF(preread_path, sub_directory, triplet_file_name, all_end_name, covariate_label, median_max_pooling):\n",
    "\n",
    "    continuous_covariate = False\n",
    "    #decide the cell data is csv or fcs\n",
    "    if os.path.exists(preread_path+'/fcs_info.csv'):\n",
    "        rawdata_format='fcs'\n",
    "    elif os.path.exists(preread_path+'/csv_info.csv'):\n",
    "        rawdata_format='csv'\n",
    "    else:\n",
    "        rawdata_format=None\n",
    "    # create file directory\n",
    "    for pick_end in all_end_name:\n",
    "        newpath = preread_path+'/' + triplet_file_name + '_' + pick_end\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "\n",
    "\n",
    "    path_base=preread_path+\"/\" + sub_directory + \"/all/\"\n",
    "    get_marker=pd.read_csv(path_base + 'marker.csv')\n",
    "    get_marker=list(get_marker.columns)\n",
    "\n",
    "    rff_dict={}\n",
    "    # generate RFF for each sample at once\n",
    "    rff_dict=preread_file(rff_dict,preread_path+'/' + rawdata_format + '_info.csv',preread_path+'/' + sub_directory + '/all/',get_marker,rawdata_format,median_max_pooling)\n",
    "\n",
    "    age_info=pd.read_csv(preread_path+'/' + rawdata_format + '_info.csv')\n",
    "\n",
    "    # decide balance sample number of train and test set\n",
    "    uni_id={}\n",
    "    for i,j in zip(age_info['file_id'],age_info['condition']):\n",
    "        uni_id[i.split('.')[0]]=j\n",
    "\n",
    "    ct_id=[]\n",
    "    co_id=[]\n",
    "\n",
    "    for i in uni_id.keys():\n",
    "        if uni_id[i]==0:\n",
    "            ct_id.append(i)\n",
    "        elif uni_id[i]==1:\n",
    "            co_id.append(i)\n",
    "\n",
    "    get_number=min(int(len(co_id)/2),int(len(ct_id)/2))\n",
    "    print(\"sample number:\",get_number)\n",
    "\n",
    "    #run for each trials for both train set RFF data and test set RFF data\n",
    "    for balence_sample_num in range(0, get_number*4, get_number*2):\n",
    "        for file_name in all_end_name:\n",
    "\n",
    "            id_lst=[]\n",
    "            label_lst=[]\n",
    "            co_lst=[]\n",
    "            rff=[]\n",
    "\n",
    "            # get revelent information in train/test set\n",
    "            id_lst,label_lst,co_lst,rff=read_files(path_base,\"train_labels_\"+file_name+\".csv\",id_lst,label_lst,co_lst,rff,rff_dict,covariate_label)\n",
    "            id_lst,label_lst,co_lst,rff=read_files(path_base,\"test_labels_\"+file_name+\".csv\",id_lst,label_lst,co_lst,rff,rff_dict,covariate_label)\n",
    "\n",
    "            # decide if is concinuous covariate\n",
    "            if len(np.unique(co_lst))>2:\n",
    "                continuous_covariate=True\n",
    "\n",
    "            if continuous_covariate:\n",
    "                med_co=np.median(age_info[covariate_label])\n",
    "\n",
    "\n",
    "            json_file_path = preread_path + \"/filenames_\"+file_name+\".json\"\n",
    "\n",
    "            # dealing with sample order in sheet \n",
    "            with open(json_file_path, 'r') as j:\n",
    "                data = j.read()\n",
    "            data=data.split('\\n')\n",
    "            json_name=[]\n",
    "            match_map=[]\n",
    "            for name_lst in data:\n",
    "                json_name.append(name_lst.split('/')[1])\n",
    "                match_map.append(id_lst.index(name_lst.split('/')[1]))\n",
    "\n",
    "            triplet=[]\n",
    "            id_lst=list(np.array(id_lst)[np.array(match_map)])\n",
    "            label_lst=list(np.array(label_lst)[np.array(match_map)])\n",
    "            co_lst=list(np.array(co_lst)[np.array(match_map)])\n",
    "            rff=list(np.array(rff)[np.array(match_map)])\n",
    "\n",
    "\n",
    "            start = balence_sample_num\n",
    "            end = balence_sample_num + get_number*2\n",
    "\n",
    "            if start == 0 and end == get_number * 2:\n",
    "                train_test='trainval'\n",
    "            else:\n",
    "                train_test='test'\n",
    "\n",
    "            #generate RFF in discrete covariate--------\n",
    "            if not continuous_covariate:\n",
    "                print('discrete covariate triplet '+ train_test + 'set in ' + file_name + ' trials')\n",
    "                for d1 in range(start,end,1):\n",
    "                    for d2 in range(start,end,1):\n",
    "                        for d3 in range(start,end,1):\n",
    "                            num_decide=[]\n",
    "                            num_decide.extend((d1,d2,d3))\n",
    "                            if len(np.unique(num_decide))==3:\n",
    "                                if (co_lst[d1]==co_lst[d2] and co_lst[d2]==co_lst[d3]) is False:\n",
    "                                    if (co_lst[d1]==co_lst[d2]):\n",
    "                                        if d1<d2:\n",
    "                                            triplet.append(str(d1)+' '+str(d3)+' '+str(d2)) # corr\n",
    "                                        else:\n",
    "                                            triplet.append(str(d2)+' '+str(d3)+' '+str(d1)) # corr\n",
    "                                    elif(co_lst[d2]==co_lst[d3]):\n",
    "                                        if d2<d3:\n",
    "                                            triplet.append(str(d2)+' '+str(d1)+' '+str(d3)) # corr\n",
    "                                        else:\n",
    "                                            triplet.append(str(d3)+' '+str(d1)+' '+str(d2)) # corr\n",
    "                                    elif(co_lst[d1]==co_lst[d3]):\n",
    "                                        if d1<d3:\n",
    "                                            triplet.append(str(d1)+' '+str(d2)+' '+str(d3)) # corr\n",
    "                                        else:\n",
    "                                            triplet.append(str(d3)+' '+str(d2)+' '+str(d1)) # corr\n",
    "            else:\n",
    "                # generate RFF in continuous covariate--------\n",
    "                print('continue covariate triplet '+ train_test + 'set in ' + file_name + ' trials')\n",
    "                for d1 in range(start,end,1):\n",
    "                    for d2 in range(start,end,1):\n",
    "                        for d3 in range(start,end,1):\n",
    "                            num_decide=[]\n",
    "                            num_decide.extend((d1,d2,d3))\n",
    "                            # print(co_lst[d1],co_lst[d2],co_lst[d3])\n",
    "                            check_bool=[int(co_lst[d1])<med_co,int(co_lst[d2])<med_co,int(co_lst[d3])<med_co]\n",
    "                            # print(check_bool)\n",
    "                            if len(np.unique(num_decide))==3:\n",
    "                                if check_bool[0]==check_bool[2] and check_bool[0]!=check_bool[1]:\n",
    "                                    triplet.append(str(d1)+' '+str(d2)+' '+str(d3)) # corr\n",
    "\n",
    "            triplet=np.unique(triplet)\n",
    "\n",
    "            final_single_trip=[] #same\n",
    "            total_dist=[] # diff\n",
    "\n",
    "            if continuous_covariate:\n",
    "                final_age_diff=[]\n",
    "                total_age_diff=[]\n",
    "            # compute each triplet difference \n",
    "            for i in triplet:\n",
    "                split_i=i.split(\" \")\n",
    "                trip_dist=compute_dist(np.array(rff[int(split_i[0])]),np.array(rff[int(split_i[1])]),np.array(rff[int(split_i[2])])) #diff\n",
    "                trip_single_dist=compute_single_dist(np.array(rff[int(split_i[0])]),np.array(rff[int(split_i[2])]))# same\n",
    "                total_dist.append(trip_dist)\n",
    "                final_single_trip.append(trip_single_dist)\n",
    "                if continuous_covariate:\n",
    "                    total_age_diff.append(compute_age(int(co_lst[int(split_i[0])]), int(co_lst[int(split_i[1])]), int(co_lst[int(split_i[2])])))\n",
    "                    final_age_diff.append(compute_single_age(int(co_lst[int(split_i[0])]),int(co_lst[int(split_i[2])])))\n",
    "                \n",
    "\n",
    "            if continuous_covariate:\n",
    "                final_single_trip=list(np.array(final_single_trip)/(np.array(final_age_diff)+1))\n",
    "                total_dist=list(np.array(total_dist)/(np.array(total_age_diff)+1))\n",
    "            # based on difference of each triplet, save in different threhold list file\n",
    "            for same_pick in range(2,11,2):\n",
    "                for diff_pick in range(2,11,2):\n",
    "                    same_percentage=same_pick/10\n",
    "                    diff_percentage=diff_pick/10\n",
    "\n",
    "                    final_trip=[]\n",
    "                    qua_same=np.quantile(final_single_trip, same_percentage)\n",
    "                    qua_diff=np.quantile(total_dist, 1 - diff_percentage)\n",
    "                    for i in range(0,len(triplet),1):\n",
    "                        if total_dist[i]>=qua_diff and final_single_trip[i]<=qua_same:\n",
    "                            final_trip.append(triplet[i])\n",
    "\n",
    "                    with open(preread_path + '/' + triplet_file_name + '_'+file_name+'/' + covariate_label + '_tripletlist_subpick_'+train_test+'_rffmax_same'+str(same_percentage)+'_diff'+str(diff_percentage)+'.txt', 'w') as f:\n",
    "                        for line in final_trip:\n",
    "                            f.write(line)\n",
    "                            f.write('\\n')\n",
    "\n",
    "                    # print(same_percentage,diff_percentage,len(final_trip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_1_02_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_2_03_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_3_04_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_4_05_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_5_07_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_6_08_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_7_11_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_8_12_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_9_14_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_10_16_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 1_11_18_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 2_12_09_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 2_13_12_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 2_14_14_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 2_15_16_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_16_01_b_PD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_17_05_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_18_08_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_19_11_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_20_14_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 3_21_17_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_22_01_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_23_04_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_24_07_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_25_10_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_26_13_b_PR_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n",
      "/Users/cookie/miniconda3/envs/py37/lib/python3.7/site-packages/flowio/flowdata.py:344: UserWarning: FCS file 4_27_16_b_SD_CD45_.fcs reported incorrect data offset. Attempting to parse data section, but event data should be reviewed before trusting this file.\n",
      "  warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number: 6\n",
      "discrete covariate triplet trainvalset in 4 trials\n",
      "discrete covariate triplet trainvalset in 44 trials\n",
      "discrete covariate triplet testset in 4 trials\n",
      "discrete covariate triplet testset in 44 trials\n"
     ]
    }
   ],
   "source": [
    "dataset_path='/Users/cookie/Documents/UNC/research/lung_cancer/data_lung_1' #path of dataset\n",
    "dataset_main_directory='lung_fcs' # main file name of dataset\n",
    "create_triplet_file='tripletlists_check' # triplet name\n",
    "trials_list=['4','44'] # seed list\n",
    "covariate_title='sex' # covariate name\n",
    "pooling='median' #median or max\n",
    "\n",
    "generate_cytocoset_RFF(dataset_path, dataset_main_directory, create_triplet_file, trials_list, covariate_title, pooling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
